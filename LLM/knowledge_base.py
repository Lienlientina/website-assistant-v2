"""
çŸ¥è­˜åº«ç®¡ç†å™¨ - ä½¿ç”¨ ChromaDB åšå‘é‡å„²å­˜å’Œæª¢ç´¢
"""
import os
import json
import shutil
from typing import List, Dict, Optional
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer


class KnowledgeBase:
    """çŸ¥è­˜åº«å‘é‡è³‡æ–™åº«ç®¡ç†å™¨"""
    
    def __init__(self, persist_directory: str = None, auto_cleanup: bool = True):
        """
        åˆå§‹åŒ–çŸ¥è­˜åº«
        
        Args:
            persist_directory: ChromaDB æŒä¹…åŒ–å„²å­˜è·¯å¾‘
            auto_cleanup: æ˜¯å¦è‡ªå‹•æ¸…ç†èˆŠçš„å‘é‡è³‡æ–™åº«
        """
        if persist_directory is None:
            persist_directory = os.path.join(
                os.path.dirname(__file__), 
                'knowledge', 
                'vectordb'
            )
        
        self.persist_directory = persist_directory
        
        # è‡ªå‹•æ¸…ç†èˆŠç‰ˆæœ¬
        if auto_cleanup:
            self._cleanup_old_versions()
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(persist_directory, exist_ok=True)
        
        # åˆå§‹åŒ– ChromaDB å®¢æˆ¶ç«¯
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        # åˆå§‹åŒ– embedding æ¨¡å‹ï¼ˆä½¿ç”¨æ”¯æ´ä¸­æ–‡çš„æ¨¡å‹ï¼‰
        print("ğŸ“¦ è¼‰å…¥ embedding æ¨¡å‹...")
        self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        print("âœ… Embedding æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
        # å–å¾—æˆ–å»ºç«‹é›†åˆ
        self.collection = self.client.get_or_create_collection(
            name="leave_system_knowledge",
            metadata={"description": "æˆå¤§è«‹å‡ç³»çµ±çŸ¥è­˜åº«"}
        )
        
        print(f"ğŸ“š çŸ¥è­˜åº«å·²åˆå§‹åŒ–ï¼Œå…± {self.collection.count()} æ¢æ–‡æª”")
    
    def _cleanup_old_versions(self):
        """æ¸…ç†èˆŠçš„å‘é‡è³‡æ–™åº«ç‰ˆæœ¬ï¼Œä¿æŒç›®éŒ„ä¹¾æ·¨"""
        if not os.path.exists(self.persist_directory):
            return
        
        try:
            # åˆ—å‡ºæ‰€æœ‰ UUID è³‡æ–™å¤¾
            uuid_folders = []
            for item in os.listdir(self.persist_directory):
                item_path = os.path.join(self.persist_directory, item)
                if os.path.isdir(item_path) and len(item) == 36:  # UUID é•·åº¦
                    uuid_folders.append(item_path)
            
            # å¦‚æœæœ‰å¤šå€‹èˆŠç‰ˆæœ¬ï¼Œåˆªé™¤æ‰€æœ‰ï¼ˆä¸‹æ¬¡æœƒé‡æ–°ç”Ÿæˆä¸€å€‹ä¹¾æ·¨çš„ï¼‰
            if len(uuid_folders) > 1:
                print(f"ğŸ§¹ æ¸…ç† {len(uuid_folders)} å€‹èˆŠçš„å‘é‡è³‡æ–™åº«ç‰ˆæœ¬...")
                for folder in uuid_folders:
                    try:
                        shutil.rmtree(folder)
                    except Exception as e:
                        print(f"âš ï¸  ç„¡æ³•åˆªé™¤ {folder}: {e}")
                print("âœ… æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def load_knowledge_from_json(self, json_path: str):
        """
        å¾ JSON æ–‡ä»¶è¼‰å…¥çŸ¥è­˜ä¸¦å»ºç«‹å‘é‡ç´¢å¼•
        
        Args:
            json_path: JSON çŸ¥è­˜åº«æ–‡ä»¶è·¯å¾‘
        """
        print(f"ğŸ“– å¾ {json_path} è¼‰å…¥çŸ¥è­˜...")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            knowledge_data = json.load(f)
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰è³‡æ–™
        if self.collection.count() > 0:
            print("âš ï¸  çŸ¥è­˜åº«å·²æœ‰è³‡æ–™ï¼Œå°‡æ¸…ç©ºå¾Œé‡æ–°è¼‰å…¥")
            # æ¸…ç©ºç¾æœ‰è³‡æ–™
            self.client.delete_collection("leave_system_knowledge")
            self.collection = self.client.create_collection(
                name="leave_system_knowledge",
                metadata={"description": "æˆå¤§è«‹å‡ç³»çµ±çŸ¥è­˜åº«"}
            )
        
        # æº–å‚™è³‡æ–™
        documents = []
        metadatas = []
        ids = []
        
        for idx, item in enumerate(knowledge_data):
            documents.append(item['content'])
            metadatas.append({
                'category': item['category'],
                'doc_id': idx
            })
            ids.append(f"doc_{idx}")
        
        # å»ºç«‹ embeddings
        print(f"ğŸ”„ å»ºç«‹ {len(documents)} å€‹æ–‡æª”çš„å‘é‡...")
        embeddings = self.embedding_model.encode(documents, show_progress_bar=True)
        
        # åŠ å…¥åˆ° ChromaDB
        self.collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids,
            embeddings=embeddings.tolist()
        )
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(documents)} æ¢çŸ¥è­˜åˆ°å‘é‡è³‡æ–™åº«")
    
    def search(self, query: str, top_k: int = 3, category: Optional[str] = None) -> List[Dict]:
        """
        æœå°‹ç›¸é—œçŸ¥è­˜ï¼ˆæ”¹é€²ç‰ˆï¼šå¢åŠ åŒç¾©è©æ“´å±•å’Œèªç¾©ç†è§£ï¼‰
        
        Args:
            query: æŸ¥è©¢å•é¡Œ
            top_k: è¿”å›å‰ k å€‹æœ€ç›¸é—œçš„çµæœ
            category: å¯é¸çš„åˆ†é¡éæ¿¾
        
        Returns:
            ç›¸é—œçŸ¥è­˜åˆ—è¡¨
        """
        # åŒç¾©è©å’Œå£èªåŒ–æ˜ å°„
        synonyms = {
            'ç”Ÿç—…': 'ç—…å‡',
            'èº«é«”ä¸èˆ’æœ': 'ç—…å‡',
            'æ„Ÿå†’': 'ç—…å‡',
            'çœ‹é†«ç”Ÿ': 'ç—…å‡',
            'æœ‰äº‹': 'äº‹å‡',
            'ç§äº‹': 'äº‹å‡',
            'å®¶è£¡æœ‰äº‹': 'äº‹å‡',
            'è¦ªäººéä¸–': 'å–ªå‡',
            'å®¶äººå»ä¸–': 'å–ªå‡',
            'è‘¬ç¦®': 'å–ªå‡',
            'ç”Ÿç†æœŸ': 'ç”Ÿç†å‡',
            'æœˆç¶“': 'ç”Ÿç†å‡',
            'ç¶“æœŸ': 'ç”Ÿç†å‡',
            'å¿ƒç†': 'å¿ƒç†èª¿é©å‡',
            'å£“åŠ›': 'å¿ƒç†èª¿é©å‡',
            'æƒ…ç·’': 'å¿ƒç†èª¿é©å‡',
            'æœŸæœ«è€ƒ': 'å­¸æœŸè€ƒè©¦å‡',
            'è€ƒè©¦': 'å­¸æœŸè€ƒè©¦å‡',
            'æœŸä¸­è€ƒ': 'å­¸æœŸè€ƒè©¦å‡',
            'ä»£è¡¨å­¸æ ¡': 'å…¬å‡',
            'æ ¡éšŠ': 'å…¬å‡',
            'æ¯”è³½': 'å…¬å‡',
            'æ´»å‹•': 'å…¬å‡',
            'æ‡·å­•': 'ç”¢å‡',
            'ç”Ÿå°å­©': 'ç”¢å‡',
            'é™ªç”¢': 'ç”¢å‡',
        }
        
        # é—œéµè©æ“´å±•
        expanded_query = query
        for synonym, official_term in synonyms.items():
            if synonym in query:
                expanded_query = query.replace(synonym, f"{synonym} {official_term}")
                break
        
        # è­‰æ˜æ–‡ä»¶ç›¸é—œè©å½™æ˜ å°„
        proof_keywords = ['è­‰æ˜', 'è¨ºæ–·æ›¸', 'æ”¶æ“š', 'è­‰æ˜æ–‡ä»¶', 'é™„è­‰æ˜', 'è¦é™„', 'éœ€è¦é™„']
        has_proof_question = any(kw in query for kw in proof_keywords)
        
        # å¤©æ•¸ç›¸é—œè©å½™
        day_keywords = ['å¹¾å¤©', 'å¤šä¹…', 'å¤šå°‘å¤©', 'å¤©æ•¸', 'ä¸Šé™', 'é™åˆ¶']
        has_day_question = any(kw in query for kw in day_keywords)
        
        # ç”³è«‹æµç¨‹ç›¸é—œè©å½™
        process_keywords = ['æ€éº¼è«‹', 'å¦‚ä½•ç”³è«‹', 'æ€éº¼è¾¦', 'æµç¨‹', 'æ­¥é©Ÿ', 'è¦æ‰¾èª°']
        has_process_question = any(kw in query for kw in process_keywords)
        
        # UI/é¸é …ç›¸é—œè©å½™ï¼ˆè¡¨ç¤ºåœ¨æ‰¾é¸é …ï¼Œä¸æ˜¯å•è¦å‰‡ï¼‰
        ui_keywords = ['æ‰¾ä¸åˆ°', 'æ²’æœ‰', 'çœ‹ä¸åˆ°', 'æ²’çœ‹åˆ°', 'å“ªè£¡', 'é¸é …', 'åœ¨å“ª']
        has_ui_question = any(kw in query for kw in ui_keywords)
        
        # æå–æŸ¥è©¢ä¸­çš„å‡åˆ¥é—œéµè©
        leave_types = ['ç—…å‡', 'äº‹å‡', 'å–ªå‡', 'ç”¢å‡', 'ç”Ÿç†å‡', 'å™¨å®˜æè´ˆå‡', 
                       'å¿ƒç†èª¿é©å‡', 'å­¸æœŸè€ƒè©¦å‡', 'å…¬å‡', 'æ­²æ™‚ç¥­å„€å‡', 'å¤šå…ƒæ–‡åŒ–å‡']
        query_leave_type = None
        for leave_type in leave_types:
            if leave_type in expanded_query:
                query_leave_type = leave_type
                break
        
        # å»ºç«‹æŸ¥è©¢ embeddingï¼ˆä½¿ç”¨æ“´å±•å¾Œçš„æŸ¥è©¢ï¼‰
        query_embedding = self.embedding_model.encode([expanded_query])[0]
        
        # å¦‚æœæª¢æ¸¬åˆ°ç‰¹å®šå‡åˆ¥ï¼Œä¸”ä¸æ˜¯UIç›¸é—œå•é¡Œï¼Œå…ˆå˜—è©¦ç”¨åˆ†é¡éæ¿¾æœå°‹
        if query_leave_type and not category and not has_ui_question:
            # å…ˆæœå°‹è©²åˆ†é¡
            category_results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k * 2,  # å–é›™å€ä»¥ä¾¿å¾ŒçºŒç¯©é¸
                where={"category": query_leave_type}
            )
            
            # å¦‚æœæ‰¾åˆ°ç›¸é—œçµæœï¼Œå„ªå…ˆä½¿ç”¨
            if category_results['documents'] and len(category_results['documents'][0]) > 0:
                formatted_results = []
                for i in range(len(category_results['documents'][0])):
                    doc = category_results['documents'][0][i]
                    
                    # æ ¹æ“šå•é¡Œé¡å‹éæ¿¾
                    if has_proof_question and 'è­‰æ˜' not in doc:
                        continue  # è·³éä¸å«è­‰æ˜è³‡è¨Šçš„æ–‡æª”
                    if has_day_question and not any(d in doc for d in ['å¤©', 'ä¸Šé™', 'é™']):
                        continue  # è·³éä¸å«å¤©æ•¸è³‡è¨Šçš„æ–‡æª”
                    
                    formatted_results.append({
                        'content': doc,
                        'category': category_results['metadatas'][0][i]['category'],
                        'distance': category_results['distances'][0][i] if 'distances' in category_results else None
                    })
                    
                    if len(formatted_results) >= top_k:
                        break
                
                if formatted_results:
                    return formatted_results[:top_k]
        
        # æº–å‚™éæ¿¾æ¢ä»¶
        where_filter = {"category": category} if category else None
        
        # æŸ¥è©¢æ›´å¤šçµæœä»¥ä¾¿é‡æ’åº
        search_k = min(top_k * 4, 12)  # å…ˆå–4å€çµæœ
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=search_k,
            where=where_filter
        )
        
        # æ ¼å¼åŒ–ä¸¦é‡æ’åºçµæœ
        formatted_results = []
        if results['documents'] and len(results['documents'][0]) > 0:
            for i in range(len(results['documents'][0])):
                doc = results['documents'][0][i]
                cat = results['metadatas'][0][i]['category']
                dist = results['distances'][0][i] if 'distances' in results else 0
                
                # è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸ï¼ˆè·é›¢è¶Šå°è¶Šå¥½ï¼‰
                score = 1.0 / (1.0 + dist)  # è½‰æ›ç‚ºç›¸ä¼¼åº¦åˆ†æ•¸
                
                # å¦‚æœå•é¡Œä¸­åŒ…å«ç‰¹å®šå‡åˆ¥ï¼Œèª¿æ•´åˆ†æ•¸
                if query_leave_type:
                    # åˆ†é¡å®Œå…¨åŒ¹é…ï¼Œå¤§å¹…æå‡
                    if cat == query_leave_type:
                        score *= 100.0
                    # å…§å®¹åŒ…å«è©²å‡åˆ¥
                    elif query_leave_type in doc:
                        score *= 10.0
                    # åŒ…å«å…¶ä»–å‡åˆ¥ä½†ä¸æ˜¯æŸ¥è©¢çš„å‡åˆ¥ï¼Œé™ä½åˆ†æ•¸
                    elif any(lt in cat or lt in doc for lt in leave_types if lt != query_leave_type):
                        score *= 0.1
                
                # æ ¹æ“šå•é¡Œé¡å‹èª¿æ•´åˆ†æ•¸
                if has_proof_question and 'è­‰æ˜' in doc:
                    score *= 2.0
                if has_day_question and any(d in doc for d in ['å¤©', 'ä¸Šé™', 'é™']):
                    score *= 2.0
                if has_process_question and any(p in doc for p in ['ç”³è«‹', 'æ ¸å‡†', 'å ±å‚™']):
                    score *= 1.5
                
                formatted_results.append({
                    'content': doc,
                    'category': cat,
                    'distance': dist,
                    'score': score
                })
            
            # æŒ‰åˆ†æ•¸æ’åºä¸¦å–å‰ top_k å€‹
            formatted_results.sort(key=lambda x: x['score'], reverse=True)
            formatted_results = formatted_results[:top_k]
            
            # ç§»é™¤å…§éƒ¨ä½¿ç”¨çš„ score æ¬„ä½
            for result in formatted_results:
                del result['score']
        
        return formatted_results
    
    def get_stats(self) -> Dict:
        """å–å¾—çŸ¥è­˜åº«çµ±è¨ˆè³‡è¨Š"""
        count = self.collection.count()
        return {
            'total_documents': count,
            'collection_name': self.collection.name
        }


def initialize_knowledge_base():
    """åˆå§‹åŒ–ä¸¦è¼‰å…¥çŸ¥è­˜åº«ï¼ˆé¦–æ¬¡ä½¿ç”¨æ™‚åŸ·è¡Œï¼‰"""
    print("ğŸš€ åˆå§‹åŒ–çŸ¥è­˜åº«...")
    
    # å»ºç«‹çŸ¥è­˜åº«å¯¦ä¾‹
    kb = KnowledgeBase()
    
    # è¼‰å…¥çŸ¥è­˜
    knowledge_path = os.path.join(
        os.path.dirname(__file__), 
        'knowledge', 
        'qa_knowledge.json'
    )
    
    if os.path.exists(knowledge_path):
        kb.load_knowledge_from_json(knowledge_path)
    else:
        print(f"âŒ æ‰¾ä¸åˆ°çŸ¥è­˜åº«æ–‡ä»¶: {knowledge_path}")
        return None
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    stats = kb.get_stats()
    print(f"ğŸ“Š çŸ¥è­˜åº«çµ±è¨ˆ: {stats}")
    
    return kb


if __name__ == "__main__":
    # æ¸¬è©¦ç”¨ï¼šåˆå§‹åŒ–çŸ¥è­˜åº«
    kb = initialize_knowledge_base()
    
    if kb:
        # æ¸¬è©¦æœå°‹ï¼ˆåŒ…å«å£èªåŒ–å•æ³•ï¼‰
        print("\nğŸ” æ¸¬è©¦æœå°‹åŠŸèƒ½...")
        test_queries = [
            "ç—…å‡éœ€è¦è­‰æ˜å—",
            "ç”Ÿç†å‡æ¯æœˆå¯ä»¥è«‹å¹¾å¤©",
            "è«‹å‡è¶…éæ™‚é™æ€éº¼è¾¦",
            "ç”Ÿç—…è¦é™„è¨ºæ–·æ›¸å—",  # å£èªåŒ–
            "ç”Ÿç†æœŸå¯ä»¥è«‹å‡å—",  # åŒç¾©è©
            "æ„Ÿå†’è«‹å‡è¦è­‰æ˜å—",  # åŒç¾©è©
            "å¿ƒç†å£“åŠ›å¯ä»¥è«‹å‡å—",  # åŒç¾©è©
            "å®¶è£¡æœ‰äº‹æ€éº¼è«‹å‡",  # å£èªåŒ–
            "æ‰¾ä¸åˆ°å…¬å‡é¸é …",
        ]
        
        for query in test_queries:
            print(f"\nå•é¡Œ: {query}")
            results = kb.search(query, top_k=2)
            for i, result in enumerate(results, 1):
                print(f"  {i}. [{result['category']}] {result['content'][:50]}...")
