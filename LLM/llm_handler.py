import os
from typing import List, Optional, Dict
import asyncio
from dotenv import load_dotenv
import base64
import re
import json
from io import BytesIO
from PIL import Image

# ä½¿ç”¨ ollama Python SDK
import ollama

# å°å…¥çŸ¥è­˜åº«ç®¡ç†å™¨
from knowledge_base import KnowledgeBase

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


class LLMHandler:
    """è™•ç† LLM å°è©±çš„ä¸»è¦é¡åˆ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ– LLM Handler"""
        self.base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.model_name = os.getenv("OLLAMA_MODEL", "qwen2.5vl:7b")
        self.temperature = float(os.getenv("TEMPERATURE", "0.7"))
        self.max_tokens = int(os.getenv("MAX_TOKENS", "1000"))
        
        # è¼‰å…¥æ¨¡å‹é…ç½®
        self.models_config = self._load_models_config()
        
        # åˆå§‹åŒ– Ollama å®¢æˆ¶ç«¯
        self.client = ollama.Client(host=self.base_url)
        
        print(f"ğŸŒ é€£æ¥åˆ°é ç«¯ Ollama: {self.base_url}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.model_name}")
        
        # åˆå§‹åŒ–çŸ¥è­˜åº«
        self.knowledge_base = self._init_knowledge_base()
        
        # è¼‰å…¥ç³»çµ±æç¤ºè©
        self.system_prompt = self._load_system_prompt()
        print(f"ğŸ“‹ ç³»çµ±æç¤ºè©å·²è¼‰å…¥")


    
    def _load_models_config(self) -> dict:
        """è¼‰å…¥æ¨¡å‹é…ç½®æª”æ¡ˆ"""
        try:
            config_path = os.path.join(os.path.dirname(__file__), 'models_config.json')
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è¼‰å…¥æ¨¡å‹é…ç½®: {e}")
            return {"available_models": [], "current_model": self.model_name}
    
    def _load_system_prompt(self) -> str:
        """å¾æ–‡ä»¶è¼‰å…¥ç³»çµ±æç¤ºè©"""
        try:
            prompt_path = os.path.join(os.path.dirname(__file__), 'knowledge', 'system_rules.txt')
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è¼‰å…¥ç³»çµ±æç¤ºè©: {e}ï¼Œä½¿ç”¨é è¨­å€¼")
            return "ä½ æ˜¯ä¸€å€‹æœ‰å¹«åŠ©çš„AIåŠ©ç†ã€‚"
    
    def _init_knowledge_base(self) -> Optional[KnowledgeBase]:
        """åˆå§‹åŒ–çŸ¥è­˜åº«"""
        try:
            kb = KnowledgeBase()
            
            # å¦‚æœçŸ¥è­˜åº«æ˜¯ç©ºçš„ï¼Œè¼‰å…¥è³‡æ–™
            if kb.collection.count() == 0:
                print("ğŸ“š çŸ¥è­˜åº«ç‚ºç©ºï¼Œé–‹å§‹è¼‰å…¥è³‡æ–™...")
                knowledge_path = os.path.join(
                    os.path.dirname(__file__), 
                    'knowledge', 
                    'qa_knowledge.json'
                )
                if os.path.exists(knowledge_path):
                    kb.load_knowledge_from_json(knowledge_path)
                else:
                    print(f"âš ï¸  æ‰¾ä¸åˆ°çŸ¥è­˜åº«æ–‡ä»¶: {knowledge_path}")
                    return None
            
            stats = kb.get_stats()
            print(f"âœ… çŸ¥è­˜åº«å·²å°±ç·’: {stats['total_documents']} æ¢æ–‡æª”")
            return kb
        except Exception as e:
            print(f"âŒ çŸ¥è­˜åº«åˆå§‹åŒ–å¤±æ•—: {e}")
            return None
    
    def list_available_models(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        return self.models_config.get("available_models", [])
    
    def switch_model(self, model_name: str):
        """åˆ‡æ›ä½¿ç”¨çš„æ¨¡å‹"""
        self.model_name = model_name
        print(f"ğŸ”„ å·²åˆ‡æ›åˆ°æ¨¡å‹: {model_name}")
    
    async def generate_response(
        self, 
        message: str, 
        image: Optional[str] = None,
        history: Optional[List[Dict]] = None
    ) -> str:
        """
        ç”Ÿæˆ AI å›æ‡‰
        
        Args:
            message: ç”¨æˆ¶è¼¸å…¥çš„æ–‡å­—è¨Šæ¯
            image: Base64 ç·¨ç¢¼çš„åœ–ç‰‡ï¼ˆå¯é¸ï¼‰
            history: å°è©±æ­·å²ï¼ˆå¯é¸ï¼‰
        
        Returns:
            AI çš„å›æ‡‰æ–‡å­—
        """
        try:
            # RAG: æª¢ç´¢ç›¸é—œçŸ¥è­˜
            relevant_knowledge = ""
            if self.knowledge_base and message:
                search_results = self.knowledge_base.search(message, top_k=3)
                if search_results:
                    relevant_knowledge = "\n\n## ç›¸é—œçŸ¥è­˜åƒè€ƒï¼š\n"
                    for i, result in enumerate(search_results, 1):
                        relevant_knowledge += f"\n{i}. [{result['category']}] {result['content']}\n"
            
            # æ§‹å»ºç³»çµ±æç¤ºè©ï¼ˆåŒ…å«æª¢ç´¢åˆ°çš„çŸ¥è­˜ï¼‰
            system_content = self.system_prompt
            if relevant_knowledge:
                system_content += relevant_knowledge
            
            # æ§‹å»ºè¨Šæ¯åˆ—è¡¨
            messages = [
                {
                    "role": "system",
                    "content": system_content
                }
            ]
            
            # æ·»åŠ å°è©±æ­·å²
            if history:
                for msg in history[-20:]:  # å–æœ€è¿‘ 20 æ¢è¨Šæ¯ï¼ˆç´„ 10 è¼ªå°è©±ï¼‰
                    if msg["role"] == "user":
                        messages.append({
                            "role": "user",
                            "content": msg["content"],
                            "images": [self._clean_base64(msg.get("image"))] if msg.get("image") else None
                        })
                    elif msg["role"] == "assistant":
                        messages.append({
                            "role": "assistant",
                            "content": msg["content"]
                        })
            
            # æ·»åŠ ç•¶å‰è¨Šæ¯
            current_message = {
                "role": "user",
                "content": message or "è«‹åˆ†æé€™å¼µåœ–ç‰‡"
            }
            
            if image:
                current_message["images"] = [self._clean_base64(image)]
            
            messages.append(current_message)
            
            # èª¿ç”¨ Ollama (åœ¨ç·šç¨‹æ± ä¸­é‹è¡ŒåŒæ­¥èª¿ç”¨)
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.client.chat(
                    model=self.model_name,
                    messages=messages,
                    options={
                        "temperature": self.temperature,
                        "num_predict": self.max_tokens
                    }
                )
            )
            
            return response['message']['content']
        
        except Exception as e:
            print(f"LLM ç”ŸæˆéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    def _clean_base64(self, image: str) -> str:
        """æ¸…ç†ä¸¦å£“ç¸® base64 åœ–ç‰‡"""
        if not image:
            return ""
        
        # ç§»é™¤ data URL å‰ç¶´
        if image.startswith('data:image'):
            image = re.sub(r'^data:image/\w+;base64,', '', image)
        
        # å£“ç¸®å¤§åœ–ç‰‡
        try:
            # è§£ç¢¼ base64
            img_data = base64.b64decode(image)
            img = Image.open(BytesIO(img_data))
            
            # å¦‚æœåœ–ç‰‡å¾ˆå¤§ï¼Œé€²è¡Œå£“ç¸®
            max_size = 1280  # æé«˜åˆ° 1280px ä»¥ä¿æŒæ–‡å­—æ¸…æ™°åº¦
            if img.width > max_size or img.height > max_size:
                # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
                ratio = min(max_size / img.width, max_size / img.height)
                new_size = (int(img.width * ratio), int(img.height * ratio))
                
                # ç¸®æ”¾åœ–ç‰‡
                img = img.resize(new_size, Image.Resampling.LANCZOS)
                
                # è½‰æ›ç‚º JPEG ä¸¦å£“ç¸®
                buffer = BytesIO()
                img.convert('RGB').save(buffer, format='JPEG', quality=85, optimize=True)  # æé«˜è³ªé‡åˆ° 85
                
                # é‡æ–°ç·¨ç¢¼ç‚º base64
                compressed_data = base64.b64encode(buffer.getvalue()).decode('utf-8')
                
                print(f"ğŸ“Š åœ–ç‰‡å·²å£“ç¸®ï¼šåŸå§‹å¤§å° {len(image)} -> å£“ç¸®å¾Œ {len(compressed_data)} (ç¯€çœ {100 - len(compressed_data)*100//len(image)}%)")
                
                return compressed_data
        except Exception as e:
            print(f"âš ï¸  åœ–ç‰‡å£“ç¸®å¤±æ•—: {e}ï¼Œä½¿ç”¨åŸå§‹åœ–ç‰‡")
        
        return image
    
    def clear_memory(self):
        """æ¸…é™¤å°è©±è¨˜æ†¶ï¼ˆä¿ç•™æ–¹æ³•ä»¥ä¿æŒ API å…¼å®¹æ€§ï¼‰"""
        pass
    
    def get_memory_variables(self):
        """ç²å–è¨˜æ†¶ä¸­çš„è®Šæ•¸ï¼ˆä¿ç•™æ–¹æ³•ä»¥ä¿æŒ API å…¼å®¹æ€§ï¼‰"""
        return {}
